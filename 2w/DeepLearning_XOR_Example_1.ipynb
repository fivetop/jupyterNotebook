{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPAqc489CtJUKk1pQAOdI9J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"gUb-oePQHm2a","executionInfo":{"status":"ok","timestamp":1664671316355,"user_tz":-540,"elapsed":512,"user":{"displayName":"Romy Oh","userId":"09196160195813226599"}}},"outputs":[],"source":["import numpy as np\n","from datetime import datetime \n","\n","np.random.seed(0)"]},{"cell_type":"code","source":["def numerical_derivative(f, x):\n","  delta_x = 1e-4\n","  grad = np.zeros_like(x)\n","    \n","  it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n","  \n","  while not it.finished:\n","      idx = it.multi_index        \n","      tmp_val = x[idx]\n","      x[idx] = float(tmp_val) + delta_x\n","      fx1 = f(x) # f(x+delta_x)\n","      \n","      x[idx] = float(tmp_val) - delta_x \n","      fx2 = f(x) # f(x-delta_x)\n","      grad[idx] = (fx1 - fx2) / (2*delta_x)\n","      \n","      x[idx] = tmp_val \n","      it.iternext()   \n","      \n","  return grad"],"metadata":{"id":"s0eEsi2rI4BA","executionInfo":{"status":"ok","timestamp":1664671319164,"user_tz":-540,"elapsed":483,"user":{"displayName":"Romy Oh","userId":"09196160195813226599"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["\n","def sigmoid(z):\n","  return 1/ (1+np.exp(-z))\n"],"metadata":{"id":"r8GKAu7_I61f","executionInfo":{"status":"ok","timestamp":1664671321473,"user_tz":-540,"elapsed":484,"user":{"displayName":"Romy Oh","userId":"09196160195813226599"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["xor_xdata = np.array([ [0,0], [0,1], [1,0], [1,1] ])  \n","xor_tdata = np.array([0, 1, 1, 0]).reshape(4,1)\n","\n","print(\"xor_xdata.shape = \", xor_xdata.shape, \", xor_tdata.shape = \", xor_tdata.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e6sQUVZ2JDPm","executionInfo":{"status":"ok","timestamp":1664671324336,"user_tz":-540,"elapsed":6,"user":{"displayName":"Romy Oh","userId":"09196160195813226599"}},"outputId":"2f7c3205-9287-4b2f-acbd-2ca62e38ba88"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["xor_xdata.shape =  (4, 2) , xor_tdata.shape =  (4, 1)\n"]}]},{"cell_type":"code","source":["input_nodes = 2\n","hidden_nodes = 2\n","output_nodes = 1\n","\n","W2 = np.random.rand(input_nodes, hidden_nodes)\n","W3 = np.random.rand(hidden_nodes, output_nodes)\n","\n","b2 = np.random.rand(hidden_nodes)\n","b3 = np.random.rand(output_nodes)\n","\n","print(W2)\n","print(b2)\n","\n","print(W3)\n","print(b3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DC-ahsazJJQ-","executionInfo":{"status":"ok","timestamp":1664672972989,"user_tz":-540,"elapsed":319,"user":{"displayName":"Romy Oh","userId":"09196160195813226599"}},"outputId":"8b1f9d47-7550-4079-f0a4-9c13ec0fd75e"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.3595079  0.43703195]\n"," [0.6976312  0.06022547]]\n","[0.21038256 0.1289263 ]\n","[[0.66676672]\n"," [0.67063787]]\n","[0.31542835]\n"]}]},{"cell_type":"code","source":["def loss_func(x, t):\n","    \n","    delta = 1e-7    # log 무한대 발산 방지\n","    \n","    z2 = np.dot(x, W2) + b2\n","    a2 = sigmoid(z2)\n","\n","    z3 = np.dot(a2, W3) + b3\n","    y = a3 = sigmoid(z3)\n","    \n","    # cross-entropy \n","    return  -np.sum( t*np.log(y + delta) + (1-t)*np.log((1 - y)+delta ) ) \n","\n","    # MSE\n","    #return np.sum((t-y)**2) / len(x)\n","    "],"metadata":{"id":"XZMkL8OmJ44n","executionInfo":{"status":"ok","timestamp":1664672979201,"user_tz":-540,"elapsed":300,"user":{"displayName":"Romy Oh","userId":"09196160195813226599"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["learning_rate = 1e-2  \n","\n","f = lambda x : loss_func(xor_xdata, xor_tdata)  \n","\n","print(\"Initial loss value = \", loss_func(xor_xdata, xor_tdata) )\n","\n","start_time = datetime.now()\n","\n","for step in range(30001):  \n","    \n","    W2 -= learning_rate * numerical_derivative(f, W2)\n","    \n","    b2 -= learning_rate * numerical_derivative(f, b2)\n","\n","    W3 -= learning_rate * numerical_derivative(f, W3)\n","    \n","    b3 -= learning_rate * numerical_derivative(f, b3)\n","    \n","    if (step % 500 == 0):\n","        print(\"step = \", step, \"loss value = \", loss_func(xor_xdata, xor_tdata) )\n","        \n","end_time = datetime.now()\n","        \n","print(\"\")\n","print(\"Elapsed Time => \", end_time - start_time)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vb96vCacKVXl","executionInfo":{"status":"ok","timestamp":1664673010485,"user_tz":-540,"elapsed":27461,"user":{"displayName":"Romy Oh","userId":"09196160195813226599"}},"outputId":"85aaec93-9645-4ffd-f72b-6980d454604b"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Initial loss value =  3.406589444274438\n","step =  0 loss value =  3.3865512653007213\n","step =  500 loss value =  2.770698227628081\n","step =  1000 loss value =  2.7700756834451017\n","step =  1500 loss value =  2.76919073697333\n","step =  2000 loss value =  2.7678959188368037\n","step =  2500 loss value =  2.7659470684103358\n","step =  3000 loss value =  2.762937445457649\n","step =  3500 loss value =  2.7581967402030116\n","step =  4000 loss value =  2.7506590739407524\n","step =  4500 loss value =  2.738736575951781\n","step =  5000 loss value =  2.720256647224606\n","step =  5500 loss value =  2.6924620134809887\n","step =  6000 loss value =  2.652052278261218\n","step =  6500 loss value =  2.5956788753128777\n","step =  7000 loss value =  2.521763797344208\n","step =  7500 loss value =  2.432924824108364\n","step =  8000 loss value =  2.3356852179956533\n","step =  8500 loss value =  2.236570648854533\n","step =  9000 loss value =  2.13775406456543\n","step =  9500 loss value =  2.034474078792777\n","step =  10000 loss value =  1.9138135727351808\n","step =  10500 loss value =  1.7551916694498715\n","step =  11000 loss value =  1.5428020836022238\n","step =  11500 loss value =  1.2896786699068188\n","step =  12000 loss value =  1.0371630774216622\n","step =  12500 loss value =  0.8228861245670335\n","step =  13000 loss value =  0.6583065317016763\n","step =  13500 loss value =  0.5366896224561242\n","step =  14000 loss value =  0.4469503426419168\n","step =  14500 loss value =  0.37970005129549156\n","step =  15000 loss value =  0.32822437102316526\n","step =  15500 loss value =  0.2879566643360137\n","step =  16000 loss value =  0.25581025849625827\n","step =  16500 loss value =  0.2296747745010595\n","step =  17000 loss value =  0.20808078835514912\n","step =  17500 loss value =  0.18998426684040884\n","step =  18000 loss value =  0.17462837295244926\n","step =  18500 loss value =  0.16145392153882832\n","step =  19000 loss value =  0.15004040869352386\n","step =  19500 loss value =  0.1400664612449703\n","step =  20000 loss value =  0.1312828148084834\n","step =  20500 loss value =  0.12349351622125881\n","step =  21000 loss value =  0.11654262160417776\n","step =  21500 loss value =  0.11030463105080489\n","step =  22000 loss value =  0.10467750658657968\n","step =  22500 loss value =  0.09957750437331661\n","step =  23000 loss value =  0.0949353000507726\n","step =  23500 loss value =  0.09069304863227698\n","step =  24000 loss value =  0.08680212859682662\n","step =  24500 loss value =  0.08322139297406125\n","step =  25000 loss value =  0.07991580037464036\n","step =  25500 loss value =  0.07685533377236427\n","step =  26000 loss value =  0.07401413937455313\n","step =  26500 loss value =  0.07136983538973145\n","step =  27000 loss value =  0.06890295308826648\n","step =  27500 loss value =  0.06659648171589512\n","step =  28000 loss value =  0.06443549555989901\n","step =  28500 loss value =  0.06240684647169778\n","step =  29000 loss value =  0.06049890889809711\n","step =  29500 loss value =  0.05870136730569109\n","step =  30000 loss value =  0.05700503803953465\n","\n","Elapsed Time =>  0:00:27.371715\n"]}]},{"cell_type":"code","source":["def predict(test_data):\n","    \n","    z2 = np.dot(test_data, W2) + b2\n","    a2 = sigmoid(z2)\n","\n","    z3 = np.dot(a2, W3) + b3\n","    y = a3 = sigmoid(z3)\n","    \n","    if y > 0.5:\n","        pred_val = 1\n","    else:\n","        pred_val = 0\n","\n","    return y, pred_val"],"metadata":{"id":"oVLKh8xTKZAW","executionInfo":{"status":"ok","timestamp":1664673014593,"user_tz":-540,"elapsed":300,"user":{"displayName":"Romy Oh","userId":"09196160195813226599"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["test_data = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n","\n","for input_data in test_data:\n","\n","    print(predict(input_data))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XMNGiWm9KmU9","executionInfo":{"status":"ok","timestamp":1664673016759,"user_tz":-540,"elapsed":3,"user":{"displayName":"Romy Oh","userId":"09196160195813226599"}},"outputId":"38cd1d42-83cc-4536-d47a-61b2787cfac1"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["(array([0.01666301]), 0)\n","(array([0.98709781]), 1)\n","(array([0.98711561]), 1)\n","(array([0.01414677]), 0)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","Y = np.array([0,0,0,1,0])\n","print(np.argmax(Y))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j36vs3QmKpsl","executionInfo":{"status":"ok","timestamp":1664678870208,"user_tz":-540,"elapsed":308,"user":{"displayName":"Romy Oh","userId":"09196160195813226599"}},"outputId":"a58e6249-05d0-4e7d-b7b3-b3234fc5e1a6"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["3\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"XSUrornnl4Vo"},"execution_count":null,"outputs":[]}]}